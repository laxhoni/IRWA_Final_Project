{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614b1eca",
   "metadata": {},
   "source": [
    "# Part 2. Indexing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe57ac",
   "metadata": {},
   "source": [
    "Author/s: <font color=\"blue\">Jhonatan Barcos Gambaro | Daniel Alexander Yearwood</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">jhonatan.barcos01@estudiant.upf.edu | danielalexander.yearwood01@estudiant.upf.edu </font>\n",
    "\n",
    "Date: <font color=\"blue\">31/10/2025</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c656cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe4afc",
   "metadata": {},
   "source": [
    "## 0. Data Preprocesing (Recap Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504ad43",
   "metadata": {},
   "source": [
    "For the implementation and development of this part of the project, we will only need to clean up the “title” and “description” variables at the textual level. Therefore, we will limit part 1 to only what is essential and necessary for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2eea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "data_path = '../../data/fashion_products_dataset.json'\n",
    "products = pd.read_json(data_path)\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "# Define new stop words that depends on the domain of the data\n",
    "stop_words_domain = {\n",
    "    'made', 'india', 'proudly', 'use', 'year', 'round', \n",
    "    'look', 'design', 'qualiti', 'day', 'make',       \n",
    "    'feel', 'perfect', 'great', 'wash', 'style',      \n",
    "}\n",
    "stop_words = stop_words.union(stop_words_domain)\n",
    "\n",
    "# Redefine clean_text function to return a list of tokens\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    textos_limpios = [word for word in word_tokens if word not in stop_words and word.isalnum()]      \n",
    "    textos_limpios = [stemmer.stem(word) for word in textos_limpios]\n",
    "    return textos_limpios\n",
    "\n",
    "\n",
    "# Apply clean_text function to the columns 'title' and 'description' of the products dataset\n",
    "products_cleaned = products.copy()\n",
    "products_cleaned['title'] = products_cleaned['title'].apply(clean_text)\n",
    "products_cleaned['description'] = products_cleaned['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creant estructures de dades (page_contents, title_index)...\n"
     ]
    }
   ],
   "source": [
    "# Define page_contents and title_index\n",
    "title_index = products['title'].to_dict()\n",
    "products['content_to_index'] = products['title'].fillna('') + ' ' + products['description'].fillna('')\n",
    "page_contents = products['content_to_index'].tolist()\n",
    "\n",
    "# Mappings between doc_ids and pids\n",
    "doc_id_to_pid = products['pid'].to_dict()\n",
    "pid_to_doc_id = {pid: i for i, pid in doc_id_to_pid.items()}\n",
    "\n",
    "N = len(page_contents) # Number of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06932a84",
   "metadata": {},
   "source": [
    "## 1. Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452393c",
   "metadata": {},
   "source": [
    "### 1.1. Build inverted index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
