{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f0e6a3",
   "metadata": {},
   "source": [
    "# Part 3. Ranking & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcee18",
   "metadata": {},
   "source": [
    "Author/s: <font color=\"blue\">Jhonatan Barcos Gambaro | Daniel Alexander Yearwood</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">jhonatan.barcos01@estudiant.upf.edu | danielalexander.yearwood01@estudiant.upf.edu </font>\n",
    "\n",
    "Date: <font color=\"blue\">20/11/2025</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c88deaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c9851",
   "metadata": {},
   "source": [
    "## 0. Data Preprocesing, Indexing and Queries (Recap Part 1-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "data_path = '../../data/fashion_products_dataset.json'\n",
    "products = pd.read_json(data_path)\n",
    "\n",
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "# Define new stop words that depends on the domain of the data\n",
    "stop_words_domain = {\n",
    "    'made', 'india', 'proudly', 'use', 'year', 'round', \n",
    "    'look', 'design', 'qualiti', 'day', 'make',       \n",
    "    'feel', 'perfect', 'great', 'wash', 'style',      \n",
    "}\n",
    "stop_words = stop_words.union(stop_words_domain)\n",
    "\n",
    "# Redefine clean_text function to build_terms to return a list of tokens\n",
    "def build_terms(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    textos_limpios = [word for word in word_tokens if word not in stop_words and word.isalnum()]      \n",
    "    textos_limpios = [stemmer.stem(word) for word in textos_limpios]\n",
    "    return textos_limpios\n",
    "\n",
    "\n",
    "# Helper function to clean numeric fields (EL TEU CODI)\n",
    "def clean_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'[^\\d.,]', '', value).replace(',', '')\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply cleaning (EL TEU CODI)\n",
    "for col in ['selling_price', 'actual_price', 'discount', 'average_rating']:\n",
    "    products[col] = products[col].apply(clean_numeric)\n",
    "\n",
    "# Assegurem que els NaN es converteixin en 0\n",
    "products['average_rating'] = products['average_rating'].fillna(0)\n",
    "\n",
    "# Apply build_terms function to the columns 'title' and 'description' of the products dataset\n",
    "products_cleaned = products.copy()\n",
    "\n",
    "products_cleaned['title'] = products_cleaned['title'].apply(build_terms)\n",
    "products_cleaned['description'] = products_cleaned['description'].apply(build_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define page_contents and title_index\n",
    "title_index = products['title'].to_dict()\n",
    "products['content_to_index'] = products['title'].fillna('') + ' ' + products['description'].fillna('')\n",
    "page_contents = products['content_to_index'].tolist()\n",
    "\n",
    "# Mappings between doc_ids and pids\n",
    "doc_id_to_pid = products['pid'].to_dict()\n",
    "pid_to_doc_id = {pid: i for i, pid in doc_id_to_pid.items()}\n",
    "\n",
    "N = len(page_contents) # Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We adapt our function create_index_tfidf from part 2 to return also the length of each document vector and the normalized term frequencies.\n",
    "def create_index_part3(documents_content, title_index_map, num_documents):\n",
    "\n",
    "    # Initialize data structures\n",
    "    index = defaultdict(list)\n",
    "    tf = defaultdict(list)\n",
    "    df = defaultdict(int)\n",
    "    idf = defaultdict(float)\n",
    "    title_index = defaultdict(str)\n",
    "    \n",
    "    doc_lengths = {} \n",
    "    \n",
    "    # Process each document\n",
    "    for page_id, content in enumerate(documents_content):\n",
    "        \n",
    "        # Build terms for the document\n",
    "        terms = build_terms(content)\n",
    "        \n",
    "        doc_lengths[page_id] = len(terms) \n",
    "\n",
    "        # Build index\n",
    "        title = title_index_map.get(page_id, \"No Title Found\")\n",
    "        title_index[page_id] = title    \n",
    "\n",
    "        \n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms): \n",
    "            try:\n",
    "                current_page_index[term][1].append(position)\n",
    "            except KeyError:\n",
    "                current_page_index[term] = [page_id, array('I', [position])]\n",
    "                \n",
    "        # Normalize term frequencies\n",
    "        norm = 0\n",
    "        for term, posting in current_page_index.items():\n",
    "            norm += len(posting[1]) ** 2\n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "        # Calculate tf normalized and DF\n",
    "        for term, posting in current_page_index.items():\n",
    "            if norm > 0:\n",
    "                tf[term].append(np.round(len(posting[1]) / norm, 4))\n",
    "            else:\n",
    "                tf[term].append(0.0)\n",
    "            \n",
    "            df[term] += 1 \n",
    "\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "\n",
    "    # Calculate IDF \n",
    "    for term in df:\n",
    "        idf[term] = np.round(np.log(float(num_documents / df[term])), 4)\n",
    "\n",
    "    return index, tf, df, idf, title_index, doc_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869b76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the TD-IDF index: 59.73 seconds\n"
     ]
    }
   ],
   "source": [
    "# Execution of the index construction\n",
    "start_time = time.time()\n",
    "\n",
    "# Call the new function\n",
    "index, tf_norm, df, idf, title_index, doc_lengths = create_index_part3(page_contents, title_index, N)\n",
    "\n",
    "# Print total time taken\n",
    "print(\"Total time to create the TD-IDF index: {} seconds\" .format(np.round(time.time() - start_time, 2)))\n",
    "\n",
    "# Calculate average document length\n",
    "avg_doc_length = sum(doc_lengths.values()) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same function search_tfidf as in part 2, but isolated here for clarity\n",
    "def find_candidate_docs(query, index):\n",
    "    query_terms = build_terms(query)\n",
    "\n",
    "    if not query_terms:\n",
    "        return set()\n",
    "\n",
    "    candidate_docs = None \n",
    "    \n",
    "    for term in query_terms:\n",
    "        \n",
    "        term_docs = {posting[0] for posting in index[term]}\n",
    "            \n",
    "        if candidate_docs is None:\n",
    "            candidate_docs = term_docs\n",
    "        else:\n",
    "            candidate_docs &= term_docs \n",
    "\n",
    "    return candidate_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = {\n",
    "        # Q1: Compulsory (validation_labels.csv)\n",
    "        \"q1\": \"women full sleeve sweatshirt cotton\",\n",
    "        \n",
    "        # Q2: Compulsory (validation_labels.csv)\n",
    "        \"q2\": \"men slim jeans blue\",\n",
    "        \n",
    "        # Q3: High Frequency Query (Based on Top DF)\n",
    "        \"q3\": \"neck solid fit\",\n",
    "\n",
    "        # Q4: Small Frequency Query (Based on Low DF)\n",
    "        \"q4\": \"trendiest glossi\",\n",
    "        \n",
    "        # Q5: Combined Query (User Simulation)\n",
    "        \"q5\": \"trendiest women\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afdd76",
   "metadata": {},
   "source": [
    "## 1. TF-IDF Ranking + cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents_tfidf(query_terms, docs_to_rank, index, df, N):\n",
    "    # Build query vector\n",
    "    query_vector = {}\n",
    "    query_term_counts = collections.Counter(query_terms) \n",
    "    \n",
    "    # Build vector for the query\n",
    "    for term, count in query_term_counts.items():\n",
    "        if term not in df: continue\n",
    "            \n",
    "        # TF de la consulta\n",
    "        tf_q = 1 + math.log10(count)\n",
    "        \n",
    "        # IDF de la consulta \n",
    "        idf_q = math.log10(N / df[term])\n",
    "        \n",
    "        query_vector[term] = tf_q * idf_q\n",
    "\n",
    "    # Calculate document scores (Dot Product)\n",
    "    # Create a dictionary {doc_id: score}\n",
    "    doc_scores = defaultdict(float)\n",
    "    \n",
    "    # Iterate over each term in the QUERY (\n",
    "    for term, query_weight in query_vector.items():\n",
    "        # Calculate the weight of this term for the documents\n",
    "        idf_d = math.log10(N / df[term]) \n",
    "        \n",
    "        for posting in index[term]:\n",
    "            doc_id = posting[0]\n",
    "            \n",
    "            if doc_id in docs_to_rank:\n",
    "                \n",
    "                # Calculate Raw TF\n",
    "                raw_tf = len(posting[1]) \n",
    "                \n",
    "                # Calculate TF of the document (logarithmic)\n",
    "                tf_d = 1 + math.log10(raw_tf)\n",
    "                \n",
    "                doc_weight = tf_d * idf_d\n",
    "\n",
    "                # Accumulate the dot product (Q_weight * D_weight)\n",
    "                doc_scores[doc_id] += query_weight * doc_weight\n",
    "    \n",
    "    # Sort documents by score\n",
    "    ranked_docs = sorted(doc_scores.keys(), key=lambda d: doc_scores[d], reverse=True)\n",
    "    \n",
    "    scores_dict = {doc_id: doc_scores[doc_id] for doc_id in ranked_docs}\n",
    "    return ranked_docs, scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: q1\n",
      "Query: women full sleeve sweatshirt cotton\n",
      "Top 5 Ranked Document IDs: [4288, 4290, 24129, 25300, 23179]\n",
      "Scores: [4.957146787053152, 4.957146787053152, 4.92628436019739, 4.92628436019739, 4.853784875481479]\n",
      "--------------------------------------------------\n",
      "Query ID: q2\n",
      "Query: men slim jeans blue\n",
      "Top 5 Ranked Document IDs: [7595, 7605, 7617, 7623, 7634]\n",
      "Scores: [4.0298552985852965, 4.0298552985852965, 4.0298552985852965, 4.0298552985852965, 4.0298552985852965]\n",
      "--------------------------------------------------\n",
      "Query ID: q3\n",
      "Query: neck solid fit\n",
      "Top 5 Ranked Document IDs: [9808, 9810, 25250, 25251, 25281]\n",
      "Scores: [1.0420485082185222, 0.9794479497805191, 0.9383224938524526, 0.9383224938524526, 0.9383224938524526]\n",
      "--------------------------------------------------\n",
      "Query ID: q4\n",
      "Query: trendiest glossi\n",
      "Top 5 Ranked Document IDs: []\n",
      "Scores: []\n",
      "--------------------------------------------------\n",
      "Query ID: q5\n",
      "Query: trendiest women\n",
      "Top 5 Ranked Document IDs: [794, 821, 826, 852, 17869]\n",
      "Scores: [9.90637288146177, 9.90637288146177, 9.90637288146177, 9.90637288146177, 9.875510454606006]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Rank test queries\n",
    "for qid, query in test_queries.items():\n",
    "    query_terms = build_terms(query)\n",
    "    candidate_docs = find_candidate_docs(query, index)\n",
    "    ranked_docs, scores = rank_documents_tfidf(query_terms, candidate_docs, index, df, N)\n",
    "\n",
    "    print('Query ID:', qid)\n",
    "    print('Query:', query)\n",
    "    print('Top 5 Ranked Document IDs:', ranked_docs[:5])\n",
    "    print('Scores:', [scores[doc_id] for doc_id in ranked_docs[:5]])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2cb03",
   "metadata": {},
   "source": [
    "## 2. BM25 Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BM25 parameters\n",
    "K1 = 1.2\n",
    "B = 0.75\n",
    "\n",
    "def rank_documents_bm25(query_terms, docs_to_rank, index, df, N, doc_lengths, avg_doc_length):\n",
    "\n",
    "    # Initialize document scores\n",
    "    doc_scores = defaultdict(float)\n",
    "    \n",
    "    # Precompute IDF for query terms\n",
    "    idf_cache = {}\n",
    "    for term in query_terms:\n",
    "        if term not in df: continue\n",
    "        # Fórmula IDF de BM25 (compte, logaritme natural)\n",
    "        df_term = df[term]\n",
    "        idf_cache[term] = math.log(1 + (N - df_term + 0.5) / (df_term + 0.5))\n",
    "\n",
    "    # Itearate over documents to rank\n",
    "    for doc_id in docs_to_rank:\n",
    "        doc_len = doc_lengths[doc_id] \n",
    "        \n",
    "        # Iterate over query terms\n",
    "        for term in query_terms:\n",
    "            if term not in idf_cache: continue \n",
    "                \n",
    "            # Obtain Raw TF for the term in the document\n",
    "            raw_tf = 0\n",
    "            for posting in index[term]:\n",
    "                if posting[0] == doc_id:\n",
    "                    raw_tf = len(posting[1]) \n",
    "                    break \n",
    "            \n",
    "            if raw_tf == 0: continue \n",
    "            \n",
    "            # BM25 TF component\n",
    "            tf_num = raw_tf * (K1 + 1)\n",
    "            tf_den = raw_tf + K1 * (1 - B + B * (doc_len / avg_doc_length))\n",
    "            tf_score = tf_num / tf_den\n",
    "            \n",
    "            # Scoring\n",
    "            doc_scores[doc_id] += idf_cache[term] * tf_score\n",
    "\n",
    "    # Sort documents by score\n",
    "    ranked_docs = sorted(doc_scores.keys(), key=lambda d: doc_scores[d], reverse=True)\n",
    "    scores_dict = {doc_id: doc_scores[doc_id] for doc_id in ranked_docs}\n",
    "    return ranked_docs, scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: q1\n",
      "Query: women full sleeve sweatshirt cotton\n",
      "Top 5 Ranked Document IDs: [4288, 4290, 14655, 25149, 25151]\n",
      "Scores: [12.100026652674897, 12.100026652674897, 11.889998681164478, 11.127435413300294, 10.922320440059151]\n",
      "--------------------------------------------------\n",
      "Query ID: q2\n",
      "Query: men slim jeans blue\n",
      "Top 5 Ranked Document IDs: [24544, 24547, 11292, 10283, 26174]\n",
      "Scores: [11.063364735088644, 11.01005550711725, 10.567155611301338, 10.567155611301338, 10.567155611301338]\n",
      "--------------------------------------------------\n",
      "Query ID: q3\n",
      "Query: neck solid fit\n",
      "Top 5 Ranked Document IDs: [12184, 12143, 12152, 12224, 24712]\n",
      "Scores: [4.392796330249203, 4.374840279049088, 4.374840279049088, 4.2867579498439055, 4.2229630784650825]\n",
      "--------------------------------------------------\n",
      "Query ID: q4\n",
      "Query: trendiest glossi\n",
      "Top 5 Ranked Document IDs: []\n",
      "Scores: []\n",
      "--------------------------------------------------\n",
      "Query ID: q5\n",
      "Query: trendiest women\n",
      "Top 5 Ranked Document IDs: [821, 794, 826, 852, 17877]\n",
      "Scores: [7.549528938396387, 7.549528938396387, 6.9611248664839005, 6.854377844127292, 5.9189284678438705]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Rank test queries\n",
    "for qid, query in test_queries.items():\n",
    "    query_terms = build_terms(query)\n",
    "    candidate_docs = find_candidate_docs(query, index)\n",
    "    ranked_docs_bm25, scores_bm25 = rank_documents_bm25(query_terms, candidate_docs, index, df, N, doc_lengths, avg_doc_length)\n",
    "\n",
    "    print('Query ID:', qid)\n",
    "    print('Query:', query)\n",
    "    print('Top 5 Ranked Document IDs:', ranked_docs_bm25[:5])\n",
    "    print('Scores:', [scores_bm25[doc_id] for doc_id in ranked_docs_bm25[:5]])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c008f4",
   "metadata": {},
   "source": [
    "## 3. NEW Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad6dce",
   "metadata": {},
   "source": [
    "### 3.1. Recap Hybrid approach (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_cleaned = products_cleaned.copy()\n",
    "\n",
    "# Convert to boolean\n",
    "products_cleaned['out_of_stock'] = products_cleaned['out_of_stock'].astype(bool)\n",
    "\n",
    "# Helper function to clean numeric fields\n",
    "def clean_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'[^\\d.,]', '', value).replace(',', '')\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply cleaning to numeric columns\n",
    "for col in ['selling_price', 'actual_price', 'discount', 'average_rating']:\n",
    "    products_cleaned[col] = products_cleaned[col].apply(clean_numeric)\n",
    "\n",
    "# Ensure discount is in valid range\n",
    "products_cleaned['discount'] = products_cleaned['discount'].clip(0, 100)\n",
    "\n",
    "#Display result to verify\n",
    "products_cleaned[['pid', 'out_of_stock', 'selling_price', 'actual_price', 'discount', 'average_rating']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents_your_score(ranked_docs_bm25, scores_bm25, products_df):\n",
    "    \"\"\"\n",
    "    Re-puntua els resultats de BM25 utilitzant una fórmula híbrida\n",
    "    que inclou la valoració (average_rating) del producte.\n",
    "    \"\"\"\n",
    "    \n",
    "    W_BM25 = 0.7  # 70% rellevància textual\n",
    "    W_RATING = 0.3 # 30% qualitat del producte\n",
    "    \n",
    "    your_scores = {}\n",
    "    \n",
    "    max_bm25_score = next(iter(scores_bm25.values())) if scores_bm25 else 0\n",
    "    if max_bm25_score == 0: \n",
    "        max_bm25_score = 1 \n",
    "        \n",
    "    MAX_RATING = 5.0\n",
    "    \n",
    "    for doc_id in ranked_docs_bm25:\n",
    "        \n",
    "        norm_bm25 = scores_bm25[doc_id] / max_bm25_score\n",
    "        \n",
    "        try:\n",
    "            rating = products_df.at[doc_id, 'average_rating']\n",
    "            if not isinstance(rating, (int, float)): rating = 0\n",
    "        except:\n",
    "            rating = 0\n",
    "            \n",
    "        norm_rating = rating / MAX_RATING\n",
    "        \n",
    "        final_score = (W_BM25 * norm_bm25) + (W_RATING * norm_rating)\n",
    "        \n",
    "        your_scores[doc_id] = final_score\n",
    "        \n",
    "    ranked_docs = sorted(your_scores.keys(), key=lambda d: your_scores[d], reverse=True)\n",
    "    scores_dict = {doc_id: your_scores[doc_id] for doc_id in ranked_docs}\n",
    "    \n",
    "    return ranked_docs, scores_dict\n",
    "\n",
    "print(\"Funció 'rank_documents_your_score' definida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
